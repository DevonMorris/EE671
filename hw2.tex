\documentclass{homework}
\usepackage{ dsfont }
\usepackage{ mathtools }
\usepackage{ commath }

\name{Timothy Devon Morris}
\course{EC En 671}
\term{Fall 2018}
\hwnum{2}

\begin{document}

%\begin{problem}[2-9]
  %Relax the requirement M3 to say
  %\[d(x, y) = 0, \quad \text{if} \quad x = y\]
  %In this fashion, we have defined a \textit{pseudometric}. Let $f: X \rightarrow \mathds{R}$ be an arbitrary function. Show that $d(x, y) = |f(x) - f(y)|$ is a pseudometric.
%\end{problem}

%\begin{solution}
  %\begin{parts}
    %\part
    %M1. We note that
    %\[ d(x,y) = |f(x) - f(y)| = |f(y) - f(x)| = d(y,x)|\]
    %\part
    %M2. Since $|f(x) - f(y)| > 0$, we have that $d(x,y) > 0$.
    %\part
    %M3. Suppose $x = y$, since $f$ is a function, we necessarily have that $f(x) = f(y)$. Thus
    %\[d(x,y) = |f(x) - f(y)| = |0| = 0\]
    %\part
    %M4. We apply to triangle inequality and see that

    %$$
    %\begin{aligned}
      %d(x,z) &= |f(x) - f(z)| = |f(x) - f(y) + f(y) - f(z)| \\
    %&\leq |f(x) - f(y)| + |f(y) - f(z)| = d(x,y) + d(y,z).
    %\end{aligned}
    %$$
  %\end{parts}
%\end{solution}

\begin{problem}[2-19]
  If $\lim \sup_{n\rightarrow\infty} a_n= A$ and $\lim \sup_{n\rightarrow\infty} b_n= B$ is it necessarily true that
  \[\lim \sup_{n\rightarrow\infty} (a_n + b_n) = A + B\]
\end{problem}

\begin{solution}
  Consider the sequences 
  \[a_n = \begin{cases} 
      0 & n\ \text{odd} \\
      1 & n\ \text{even}\\
   \end{cases}
  \]
  and
  \[b_n = \begin{cases} 
      0 & n\ \text{odd} \\
      -1 & n\ \text{even}\\
   \end{cases}
  \]
  We quickly seen that $\lim \sup_{n\rightarrow\infty} a_n= 1$ and $\lim \sup_{n\rightarrow\infty} b_n= 0$. But
  \[ a_n + b_n = 0 \quad \forall n\]
  Thus, 
  \[\lim \sup_{n\rightarrow\infty} (a_n + b_n)  = 0 \neq 0 + 1 = 1\]
  Therefore the above statement is not true.
\end{solution}

\begin{problem}[2-20]
  Show that if $\{x_n\}$ is a sequence such that 
  \[ d(x_{n+1}, x_n) < Cr^n\]
  for $0 \leq r < 1$, then $\{x_n\}$ is a Cauchy sequence
\end{problem}

\begin{solution}
  Given $\epsilon > 0$, choose $N > \log{(\epsilon(1-r)/C)}/\log{r}$. Without loss of generality, let $n > m \geq N$ Thus we have
  \[d(x_m, x_n) \leq d(x_m, x_{m+1}) + d(x_{m+1}, x_{m+2}) + \dots + d(x_{n-1}, x_{n}) \leq \sum_{i = m}^{\infty} d(x_{i}, x_{i+1})\]
  Using the identities for the infinite geometric series, (we can only do this because the series is absolutely convergent).
  \[d(x_m, x_n) \leq Cr^m\sum_{i=0}^{\infty} r^i < Cr^N\sum_{i=0}^{\infty} r^i = \frac{Cr^N}{1 - r} < \epsilon \]
  
\end{solution}

\begin{problem}[2-22]
  Show that if a sequence $\{x_n\}$ is convergent, then it is a Cauchy sequence.
\end{problem}

\begin{solution}
  Assume that $\{x_n\}$ is convergent and has a limit of $x^*$. Thus, given $\epsilon > 0$ there exists an $N$ such that $d(x_n, x^*) < \epsilon/2 \quad \forall n \geq N$. Now let $m,n \geq N$. Consider $d(x_m, x_n)$.
  \[d(x_m, x_n) \leq d(x_m, x^*) + d(x*,x_n) < \epsilon/2 + \epsilon/2 = \epsilon\]
Thus, every convergent sequence is a cauchy sequence.
\end{solution}

\begin{problem}[2-33]
  Prove the reverse triangle inequality
  \[|\norm{x} - \norm{y}| \leq \norm{x-y}\]
\end{problem}

\begin{solution}
  We will prove each case for the absolute value. Note, It suffices to show that 
  \[\norm{x} \leq \norm{x - y} + \norm{y}\]
  \[\norm{y} \leq \norm{x - y} + \norm{x}\]
  This is easily shown using the triangle inequality for norms
  \[\norm{x} = \norm{x - y + y} \leq \norm{x - y} + \norm{y}\]
  \[\norm{y} = \norm{y - x + x} \leq \norm{y - x} + \norm{x} = \norm{x - y} + \norm{x}\]
\end{solution}

\begin{problem}[2-42]
  Which of the following determines an inner product over $C^1[0,1]$.
  \begin{parts}
    \part
    \[\langle f, g \rangle = \int_0^1 f'(t)g'(t)\ dt + f(0)g(0)\]
    \part
    \[\langle f, g \rangle = \int_0^1 f'(t)g'(t)\ dt\]
  \end{parts}
\end{problem}

\begin{solution}
  \begin{parts}
    \part
    We will show that the inner product is consistent with the 4 axioms below

    IP1.
    \[
    \langle f, g \rangle = \int_0^1 f'(t)g'(t)\ dt + f(0)g(0) = \int_0^1 g'(t)f'(t) + g(0)f(0) = \langle g, f\rangle
    \]
    IP2.
    \[
      \langle \alpha f, g \rangle = \int_0^1 \alpha f'(t)g'(t)\ dt + \alpha f(0)g(0) =
      \alpha\left(\int_0^1 f'(t)g'(t)\ dt + f(0)g(0)\right) = \alpha\langle f, g\rangle
    \]
    IP3.
    $$
    \begin{aligned}
      \langle f + h, g \rangle = &\int_0^1 (f + h)'(t)g'(t)\ dt + (f + h)(0)g(0) =
      \int_0^1f'(t)g'(t)\ dt + f(0)g(0) + \\
      &\int_0^1 h'(t)g'(t)\ dt + h(0)g(0) = \langle f, g \rangle + \langle h, g \rangle
   \end{aligned}
   $$
   IP4.
   Consider $\langle f, f \rangle$
   $$
   \langle f, f \rangle = \int_0^1 f'(t)^2\ dt + f(0)^2 \geq 0
   $$
   If $f$ is the zero function then $\langle f, f\rangle$ = 0. Thus, assume $\langle f, f\rangle = 0$. By necessity, we must have that $f(0) = 0$ and $\int_0^1 f'(t)^2\ dt =0$. This implies that $f'(t) = 0 \quad \forall t \in (0,1)$. Thus we have the initial value problem
   \[ f'(t) = 0 \quad f(0) = 0\]
   Which has the solution $f(t) = 0$. Therefore this is an inner product.
   \part
   We will show that this candidate inner product violates IP4. Consider the function $f(t) = c$, where $c \in \mathds{R}/\{0\}$. Note that $f'(t) = 0$. Therefore, $\langle f, f\rangle$ = 0 even though $f \neq 0$.
  \end{parts}
\end{solution}

\begin{problem}[2-43]
  Show that for an induced norm $\norm{\cdot}$ over a real vector space, the following hold
  \begin{parts}
  \part
  The parallelogram law
  \[ \norm{x + y}^2 + \norm{x - y}^2 = 2\norm{x}^2 + 2\norm{y}^2\]
  \part
  The polarization identity
  \[ \langle x, y \rangle = \frac{\norm{x + y}^2 - \norm{x - y}^2}{4}\]
  \end{parts}
\end{problem}

\begin{solution}
  \begin{parts}
    \part
    Expanding $\norm{x+y}^2$ and $\norm{x-y}^2$ in terms of the inner product gives us
    $$
    \begin{aligned}
      \norm{x+y}^2 = \langle x,x \rangle + 2\langle x, y\rangle + \langle y, y\rangle \\
      \norm{x-y}^2 = \langle x,x \rangle - 2\langle x, y\rangle + \langle y, y\rangle
    \end{aligned}
    $$
    Adding these two expressions gives us
    \[\norm{x+y}^2 + \norm{x-y}^2 = 2\langle x, x\rangle + 2\langle y, y \rangle = 2\norm{x}^2 + 2\norm{y}^2\]
    \part
    Using the same expansion from part a gives us
    $$
    \begin{aligned}
      \norm{x+y}^2 = \langle x,x \rangle + 2\langle x, y\rangle + \langle y, y\rangle \\
      \norm{x-y}^2 = \langle x,x \rangle - 2\langle x, y\rangle + \langle y, y\rangle
    \end{aligned}
    $$
    Now, subtracting these expressions gives us
    \[ 4\langle x, y\rangle = \norm{x + y}^2 - \norm{x - y}^2\]
    Which implies
    \[ \langle x, y\rangle = \frac{\norm{x + y}^2 - \norm{x - y}^2}{4}\]
  \end{parts}
\end{solution}

\begin{problem}[2-49]
  Show that a set of nonzero vectors $\{p_1, p_2, \dots, p_m\}$ that are mutually orthogonal, i.e.
  \[ \langle p_j, p_k\rangle = 0, \quad \text{if} j\neq k\]
  are linearly independent.
\end{problem}

\begin{solution}
  Suppose that a set of nonzero vectors $\{p_1, p_2, \dots, p_m\}$ are mutually orthogonal. Now assume to the contrary, that they are linearly dependent. Thus there exist scalars $\{\alpha_1, \alpha_2, \dots, \alpha_m\}$ not all zero such that
  \[\alpha_1 p_1 + \alpha_2 p_2 + \dots + \alpha_m p_m = 0\]
  Taking the inner product of each side with $p_k$, where $1\leq k \leq m$ gives us that
  \[ \alpha_k \norm{p_k}^2 = 0\]
  Since $k$ is arbitrary, we can choose $k$ to match a nonzero $\alpha_k$ and we see that
  \[ \norm{p_k}^2 = 0\]
  Thus contradicting our supposition. Therefore, the set is linearly independent.
\end{solution}

\end{document}
